using Random: shuffle

export sgd!

function sgd!(network::Network, training_data, mini_batch_size, Î·, epochs=1)
    for _ in 1:epochs
        training_data = shuffle(training_data)
        mini_batches = Iterators.partition(training_data, mini_batch_size)
        for mini_batch in mini_batches
            update_mini_batch!(network, mini_batch, Î·)
        end
    end
    return network
end

function update_mini_batch!(network::Network, mini_batch, Î·)
    ğ¯w, ğ¯ğ—¯ = similar(collect(network.weights)), similar(collect(network.biases))
    for (x, y) in mini_batch
        ğ¯wâ±, ğ¯ğ—¯â± = Backpropagator(sigmoid, sigmoidâ€²)(network, x, y)
        ğ¯w .+= ğ¯wâ±
        ğ¯ğ—¯ .+= ğ¯ğ—¯â±
    end
    Î·â€² = Î· / length(mini_batch)
    # Update each layer's weights and biases
    for (wâ±¼â‚–, bâ±¼, âˆ‡wâ±¼â‚–, âˆ‡bâ±¼) in zip(network.weights, network.biases, ğ¯w, ğ¯ğ—¯)
        wâ±¼â‚–[:, :] .-= Î·â€² * âˆ‡wâ±¼â‚–
        bâ±¼[:] .-= Î·â€² * âˆ‡bâ±¼
    end
    return network
end
