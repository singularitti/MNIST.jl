using Random: shuffle
using Statistics: mean

export feedforward, computecost, sgd!

function feedforward(network::Network, ğš)
    for (w, ğ›) in (network.weights, network.biases)
        ğš = w * ğš .+ ğ›
    end
    return ğš
end

function computecost(network::Network, input, desired_output)
    output = feedforward(network, input)
    return sum(abs2, desired_output .- output)
end

function sgd!(network::Network, training_data, mini_batch_size, Î·, epochs=1)
    for _ in 1:epochs
        training_data = shuffle(training_data)
        mini_batches = Iterators.partition(training_data, mini_batch_size)
        for mini_batch in mini_batches
            update_mini_batch!(network, mini_batch, Î·)
        end
    end
    return network
end

function update_mini_batch!(network::Network, mini_batch, Î·)
    networks = map(mini_batch) do (x, y)
        backprop(network, x, y)  # For all layers
    end
    âˆ‡w, âˆ‡b = mean(network.weights for network in networks),
    mean(network.weights for network in networks)
    # Update each layer's weights and biases
    for (wâ±¼â‚–, bâ±¼, âˆ‡wâ±¼â‚–, âˆ‡bâ±¼) in zip(network.weights, network.biases, âˆ‡w, âˆ‡b)
        wâ±¼â‚–[:, :] .-= Î· * âˆ‡wâ±¼â‚–
        bâ±¼[:] .-= Î· * âˆ‡bâ±¼
    end
    return network
end

function backprop(network::Network, x, y) end

sigmoid(z) = 1 / (1 + exp(-z))

sigmoidâ€²(z) = sigmoid(z) * (1 - sigmoid(z))
